<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>Day 14 - Thursday, January 14, 2021 - zainsci-blog</title><meta name="next-head-count" content="3"/><link rel="preload" href="/blog/_next/static/css/7326876a07940d477f61.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/7326876a07940d477f61.css" data-n-g=""/><noscript data-n-css=""></noscript><link rel="preload" href="/blog/_next/static/chunks/webpack-68b33a983b217570410c.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/framework-9bf9f61c21c28db23d5b.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/597-b00db1c133ea663e36f8.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/778-0eca3c12d3dbfbf41974.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/main-9ca82ec4d4aca520c43d.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/pages/_app-d0383bb574e856e8c82c.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/885-1a3ba520d6a771969c4b.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/pages/posts/%5Bslug%5D-38ecf2de6125847544d2.js" as="script"/></head><body><div id="__next"><header><h3 class="logo">zainsci-blog</h3><nav class="nav"><ul class="nav__list"><li class="nav__item"><a href="/" class="nav__link">Home</a></li><li class="nav__item"><a href="/portfolio" class="nav__link">Portfolio</a></li><li class="nav__item"><a href="/about" class="nav__link">About</a></li><li class="nav__item"><a href="/contact" class="nav__link">Contact</a></li><li class="nav__item"><div class="toggler"><a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="currentColor" stroke-width="2" class="feather feather-moon"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg></a></div></li></ul></nav></header><main><div class="share"><p>Share With Others</p><div class="share__buttons"><div class="share__button"><a href="https://twitter.com/intent/tweet?url=https://zainsci.github.ioday-14&amp;text=Day 14 - Thursday, January 14, 2021
&amp;hashtags=zainsci,Python,Random" target="_blank" rel="noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" class="feather feather-twitter"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg></a></div><div class="share__button"><a href="https://www.facebook.com/sharer/sharer.php?u=zainsci.github.io%2Fblogday-14" target="_blank" rel="noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" class="feather feather-facebook"><path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path></svg></a></div></div></div><article class="blog__post" itemscope="" itemType="http://schema.org/Article"><header><h1 itemProp="headline">Day 14 - Thursday, January 14, 2021</h1><div itemProp="datePublished">2021-01-14</div></header><section itemProp="articleBody"><p>There was <a href="https://www.reddit.com/r/MachineLearning/comments/kuc6tz/d_a_demo_from_1993_of_32yearold_yann_lecun/">this</a> video I saw some days ago on Reddit where a 32-year-old programmer named Yann LeCun demonstrates "World's first Convolutional Network for Text Recognition" and I was amazed that this video was 27 years old and they had much weaker computer in terms of processing power and computation and still they were able to do this and here I am trying my best to extract text from some images with much faster computer than they had and also much better softwares and still having no luck.</p>
<p>I decided to learn PyTesseract (Python-tesseract is an optical character recognition (OCR) tool for python and Tesseract is an OCR engine by Google) when I had some images at work where I had to manually add data from the image to the accounting software and then just like every lazy programmer spends 8 hours trying to automate 5-minute task, I tried to automate the task by extracting text from the images and adding it accounting software with Python.</p>
<p>The first obstacle was to extract text from the image which when I read the pytesseract documentation example seemed pretty easy task to do but it was not especially when the image is not in good quality and some words are hard to read by even a by human.</p>
<p>So I spent some time readng some articles with some examples explaining how to extract text from images and but there were too many new concepts coming my way that i didn't understood so I quit it that day and left it on the future and now today again I wanted to do that same thing and for those same images and I am thinking of learning this now</p>
<h2>What I Learned Today</h2>
<h3>üíª Programming</h3>
<ul>
<li>PyTesseract - I didn't learn all of it just started learning it and i think it will take some time, a long time, to really get the expected results from it but its okay as long as I learn somthing from it. here are some good articles i read today on extracting text from images. <a href="https://developer.ibm.com/languages/python/tutorials/document-scanner/">One</a>, <a href="https://medium.com/analytics-vidhya/extracting-text-from-images-using-python-315ed54d90e8">Two</a>.</li>
</ul>
<h3>üóæ Langauge[<span lang="ja">Êó•Êú¨Ë™û</span>]</h3>
<ul>
<li><span lang="ja"><strong>„ÅäÂúüÁî£</strong> („Åä„Åø„ÇÑ„Åí)</span> Souvenir. <span lang="ja">Âúü</span>: Soil.</li>
<li><span lang="ja"><strong>ÂÑÑ</strong> („Åä„Åè)</span> Hundred Million.</li>
<li><span lang="ja"><strong>ÊÑèÂë≥</strong> („ÅÑ„Åø)</span> Meaning.</li>
</ul>
</section></article><br/><br/><br/><hr/></main><footer class="footer"><div>Copyright ¬© <!-- -->2021<!-- --> zainsci</div><div>Built with Next.js by<!-- --> <a href="https://zainsci.github.io" target="_blank" rel="noopener noreferrer">zainsci</a></div><div><div><div class="social__icons undefined"><a href="https://twitter.com/zainsci" target="_blank" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" class="feather feather-twitter"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg></a><a href="https://instagram.com/zainsci" target="_blank" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" class="feather feather-instagram"><rect x="2" y="2" width="20" height="20" rx="5" ry="5"></rect><path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z"></path><line x1="17.5" y1="6.5" x2="17.51" y2="6.5"></line></svg></a><a href="https://github.com/zainsci" target="_blank" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></div></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Day 14 - Thursday, January 14, 2021","date":"2021-01-14","slug":"day-14","content":"\u003cp\u003eThere was \u003ca href=\"https://www.reddit.com/r/MachineLearning/comments/kuc6tz/d_a_demo_from_1993_of_32yearold_yann_lecun/\"\u003ethis\u003c/a\u003e video I saw some days ago on Reddit where a 32-year-old programmer named Yann LeCun demonstrates \"World's first Convolutional Network for Text Recognition\" and I was amazed that this video was 27 years old and they had much weaker computer in terms of processing power and computation and still they were able to do this and here I am trying my best to extract text from some images with much faster computer than they had and also much better softwares and still having no luck.\u003c/p\u003e\n\u003cp\u003eI decided to learn PyTesseract (Python-tesseract is an optical character recognition (OCR) tool for python and Tesseract is an OCR engine by Google) when I had some images at work where I had to manually add data from the image to the accounting software and then just like every lazy programmer spends 8 hours trying to automate 5-minute task, I tried to automate the task by extracting text from the images and adding it accounting software with Python.\u003c/p\u003e\n\u003cp\u003eThe first obstacle was to extract text from the image which when I read the pytesseract documentation example seemed pretty easy task to do but it was not especially when the image is not in good quality and some words are hard to read by even a by human.\u003c/p\u003e\n\u003cp\u003eSo I spent some time readng some articles with some examples explaining how to extract text from images and but there were too many new concepts coming my way that i didn't understood so I quit it that day and left it on the future and now today again I wanted to do that same thing and for those same images and I am thinking of learning this now\u003c/p\u003e\n\u003ch2\u003eWhat I Learned Today\u003c/h2\u003e\n\u003ch3\u003eüíª Programming\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ePyTesseract - I didn't learn all of it just started learning it and i think it will take some time, a long time, to really get the expected results from it but its okay as long as I learn somthing from it. here are some good articles i read today on extracting text from images. \u003ca href=\"https://developer.ibm.com/languages/python/tutorials/document-scanner/\"\u003eOne\u003c/a\u003e, \u003ca href=\"https://medium.com/analytics-vidhya/extracting-text-from-images-using-python-315ed54d90e8\"\u003eTwo\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eüóæ Langauge[\u003cspan lang=\"ja\"\u003eÊó•Êú¨Ë™û\u003c/span\u003e]\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cspan lang=\"ja\"\u003e\u003cstrong\u003e„ÅäÂúüÁî£\u003c/strong\u003e („Åä„Åø„ÇÑ„Åí)\u003c/span\u003e Souvenir. \u003cspan lang=\"ja\"\u003eÂúü\u003c/span\u003e: Soil.\u003c/li\u003e\n\u003cli\u003e\u003cspan lang=\"ja\"\u003e\u003cstrong\u003eÂÑÑ\u003c/strong\u003e („Åä„Åè)\u003c/span\u003e Hundred Million.\u003c/li\u003e\n\u003cli\u003e\u003cspan lang=\"ja\"\u003e\u003cstrong\u003eÊÑèÂë≥\u003c/strong\u003e („ÅÑ„Åø)\u003c/span\u003e Meaning.\u003c/li\u003e\n\u003c/ul\u003e\n","tags":["Python","Random"]}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"day-14"},"buildId":"Fy0YqD2NVJUYLq0OzYr_B","assetPrefix":"/blog","isFallback":false,"gsp":true}</script><script nomodule="" src="/blog/_next/static/chunks/polyfills-8683bd742a84c1edd48c.js"></script><script src="/blog/_next/static/chunks/webpack-68b33a983b217570410c.js" async=""></script><script src="/blog/_next/static/chunks/framework-9bf9f61c21c28db23d5b.js" async=""></script><script src="/blog/_next/static/chunks/597-b00db1c133ea663e36f8.js" async=""></script><script src="/blog/_next/static/chunks/778-0eca3c12d3dbfbf41974.js" async=""></script><script src="/blog/_next/static/chunks/main-9ca82ec4d4aca520c43d.js" async=""></script><script src="/blog/_next/static/chunks/pages/_app-d0383bb574e856e8c82c.js" async=""></script><script src="/blog/_next/static/chunks/885-1a3ba520d6a771969c4b.js" async=""></script><script src="/blog/_next/static/chunks/pages/posts/%5Bslug%5D-38ecf2de6125847544d2.js" async=""></script><script src="/blog/_next/static/Fy0YqD2NVJUYLq0OzYr_B/_buildManifest.js" async=""></script><script src="/blog/_next/static/Fy0YqD2NVJUYLq0OzYr_B/_ssgManifest.js" async=""></script></body></html>